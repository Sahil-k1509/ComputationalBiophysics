{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d419f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 11:41:56.350149: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-05 11:41:56.351281: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-05 11:41:56.375016: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-05 11:41:56.375545: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-05 11:41:56.848333: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,sys\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a893c805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing path of files\n",
    "hlaPATH = \"./Scrapper/hla_msa.txt\"\n",
    "afterPcaPATH = './after_pca.txt'\n",
    "epitopePATH = './remove0123_sample100.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dea6f3",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca9dbf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the after_pca file which contains 12 most relevant physicochemical properties after PCA\n",
    "after_pca = np.loadtxt(afterPcaPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d60ebff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a4c677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the epitope data\n",
    "ori = pd.read_csv(epitopePATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15b5ee05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peptide</th>\n",
       "      <th>HLA</th>\n",
       "      <th>immunogenicity</th>\n",
       "      <th>test</th>\n",
       "      <th>respond</th>\n",
       "      <th>potential</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DYIIKIWKL</td>\n",
       "      <td>HLA-A*2402</td>\n",
       "      <td>Negative</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.267811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VPVVEDALM</td>\n",
       "      <td>HLA-B*3501</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.969088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MMQDREDQSI</td>\n",
       "      <td>HLA-A*0201</td>\n",
       "      <td>Negative</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.108715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VEMTEPYNL</td>\n",
       "      <td>HLA-B*4402</td>\n",
       "      <td>Negative</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.294861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FIFSYVVAV</td>\n",
       "      <td>HLA-A*0201</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.973914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      peptide         HLA immunogenicity  test  respond  potential\n",
       "0   DYIIKIWKL  HLA-A*2402       Negative     5        0   0.267811\n",
       "1   VPVVEDALM  HLA-B*3501       Positive     0        0   0.969088\n",
       "2  MMQDREDQSI  HLA-A*0201       Negative    24        0   0.108715\n",
       "3   VEMTEPYNL  HLA-B*4402       Negative     4        0   0.294861\n",
       "4   FIFSYVVAV  HLA-A*0201       Positive     0        0   0.973914"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sampling the data and re-indexing the same\n",
    "ori = ori.sample(frac=1, replace=False, random_state = 4).set_index(pd.Index(np.arange(ori.shape[0])))\n",
    "ori.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f7fa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283bba4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading HLA data\n",
    "df = pd.read_csv(hlaPATH,header=None,delim_whitespace=True)\n",
    "df.columns = [\"HLA\",\"pseudo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4666ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2a0db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making dictionary of HLA data by mapping HLA with its pseudo-sequence\n",
    "hla_dic = {row[\"HLA\"]:row[\"pseudo\"] for index, row in df.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a68d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "hla_dic[\"HLA-A*0101\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab55828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the HLA enteries in a list\n",
    "inventory = list(hla_dic.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ca32ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1826b465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating dic_inventory for mapping the HLA sequences according to their types\n",
    "dic_inventory = {}\n",
    "for hla in inventory:\n",
    "    if hla[4] in dic_inventory:\n",
    "        if hla[6:8] in dic_inventory[hla[4]]:\n",
    "            dic_inventory[hla[4]][hla[6:8]].append(hla[8:])\n",
    "        else:\n",
    "            dic_inventory[hla[4]][hla[6:8]] =[]\n",
    "            dic_inventory[hla[4]][hla[6:8]].append(hla[8:])\n",
    "    else:\n",
    "        dic_inventory[hla[4]] = {}\n",
    "        dic_inventory[hla[4]][hla[6:8]] =[]\n",
    "        dic_inventory[hla[4]][hla[6:8]].append(hla[8:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47ed39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for encoding the HLA and peptide using aaindex and mapping the same to immunogenic potential,taken \n",
    "# directly from deepimmuno, for maintaining uniformity of the input data\n",
    "\n",
    "def rescue_unknown_hla(hla, dic_inventory):\n",
    "    type_ = hla[4]\n",
    "    first2 = hla[6:8]\n",
    "    last2 = hla[8:]\n",
    "    big_category = dic_inventory[type_]\n",
    "    #print(hla)\n",
    "    if not big_category.get(first2) == None:\n",
    "        small_category = big_category.get(first2)\n",
    "        distance = [abs(int(last2) - int(i)) for i in small_category]\n",
    "        optimal = min(zip(small_category, distance), key=lambda x: x[1])[0]\n",
    "        return 'HLA-' + str(type_) + '*' + str(first2) + str(optimal)\n",
    "    else:\n",
    "        small_category = list(big_category.keys())\n",
    "        distance = [abs(int(first2) - int(i)) for i in small_category]\n",
    "        optimal = min(zip(small_category, distance), key=lambda x: x[1])[0]\n",
    "        return 'HLA-' + str(type_) + '*' + str(optimal) + str(big_category[optimal][0])\n",
    "\n",
    "def aaindex(peptide,after_pca):\n",
    "\n",
    "    amino = 'ARNDCQEGHILKMFPSTWYV-'\n",
    "    matrix = np.transpose(after_pca)   # [12,21]\n",
    "    encoded = np.empty([len(peptide), 12])  # (seq_len,12)\n",
    "    for i in range(len(peptide)):\n",
    "        query = peptide[i]\n",
    "        if query == 'X': query = '-'\n",
    "        query = query.upper()\n",
    "        encoded[i, :] = matrix[:, amino.index(query)]\n",
    "\n",
    "    return encoded\n",
    "\n",
    "def hla_data_aaindex(hla_dic,hla_type,after_pca,dic_inventory):    # return numpy array [34,12,1]\n",
    "    try:\n",
    "        seq = hla_dic[hla_type]\n",
    "    except KeyError:\n",
    "        hla_type = rescue_unknown_hla(hla_type,dic_inventory)\n",
    "        seq = hla_dic[hla_type]\n",
    "    encode = aaindex(seq,after_pca)\n",
    "    encode = encode.reshape(encode.shape[0], encode.shape[1], -1)\n",
    "    return encode\n",
    "\n",
    "def peptide_data_aaindex(peptide,after_pca):   # return numpy array [10,12,1]\n",
    "    length = len(peptide)\n",
    "    if length == 10:\n",
    "        encode = aaindex(peptide,after_pca)\n",
    "    elif length == 9:\n",
    "        peptide = peptide[:5] + '-' + peptide[5:]\n",
    "        encode = aaindex(peptide,after_pca)\n",
    "    encode = encode.reshape(encode.shape[0], encode.shape[1], -1)\n",
    "    return encode\n",
    "\n",
    "\n",
    "def construct_aaindex(ori,hla_dic,after_pca,dic_inventory):\n",
    "    series = []\n",
    "#     res = pd.DataFrame(columns = ['encode_pep', 'encode_hla', 'immuno'])\n",
    "    for i in range(ori.shape[0]):\n",
    "        peptide = ori['peptide'].iloc[i]\n",
    "        hla_type = ori['HLA'].iloc[i]\n",
    "        immuno = np.array(ori['potential'].iloc[i]).reshape(1,-1)   # [1,1]\n",
    "\n",
    "        encode_pep = peptide_data_aaindex(peptide,after_pca)    # [10,12]\n",
    "\n",
    "        encode_hla = hla_data_aaindex(hla_dic,hla_type,after_pca,dic_inventory)   # [64,12]\n",
    "#         res.loc[i] = [encode_pep.reshape(10,12).astype(float), encode_hla.reshape(64,12).astype(float), immuno]\n",
    "        series.append((encode_pep, encode_hla, immuno))\n",
    "#     return res\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2244d370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating the final database\n",
    "dataset = construct_aaindex(ori, hla_dic, after_pca,dic_inventory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1d12cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating input1, input2 and labels while preserving the indexing\n",
    "input1 = np.empty([len(dataset),10,12,1])\n",
    "input2 = np.empty([len(dataset),64,12,1])\n",
    "label = np.empty([len(dataset),1])\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    input1[i,:,:,:] = dataset[i][0]\n",
    "    input2[i,:,:,:] = dataset[i][1]\n",
    "    label[i,:] = dataset[i][2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2bfa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into training (80%) and validation (20%) \n",
    "array = np.arange(len(dataset))\n",
    "train_index = np.random.choice(array,int(len(dataset)*0.8),replace=False)\n",
    "valid_index = [item for item in array if item not in train_index]\n",
    "input1_train = input1[train_index]\n",
    "input1_val = input1[valid_index]\n",
    "input2_train = input2[train_index]\n",
    "input2_val = input2[valid_index]\n",
    "label_train = label[train_index]\n",
    "label_val = label[valid_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8235ebc",
   "metadata": {},
   "source": [
    "# Model 1 - CNN \n",
    "(After modifying kernel of deepImmuno to match updated data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36052236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildCNN():\n",
    "    input_pep = keras.Input(shape=(10, 12, 1))\n",
    "    input_mhc = keras.Input(shape=(64, 12, 1))\n",
    "\n",
    "    x = layers.Conv2D(filters=16, kernel_size=(2, 12))(input_pep)  # 9\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = keras.activations.relu(x)\n",
    "    x = layers.Conv2D(filters=32, kernel_size=(2, 1))(x)    # 8\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = keras.activations.relu(x)\n",
    "    x = layers.MaxPool2D(pool_size=(2, 1), strides=(2, 1))(x)  # 4\n",
    "    x = layers.Flatten()(x)\n",
    "    x = keras.Model(inputs=input_pep, outputs=x)\n",
    "\n",
    "    y = layers.Conv2D(filters=16, kernel_size=(33, 12))(input_mhc)     # 32\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = keras.activations.relu(y)\n",
    "    y = layers.MaxPool2D(pool_size=(2, 1), strides=(2, 1))(y)  # 16\n",
    "    y = layers.Conv2D(filters=32,kernel_size=(9,1))(y)    # 8\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = keras.activations.relu(y)\n",
    "    y = layers.MaxPool2D(pool_size=(2, 1),strides=(2,1))(y)  # 4\n",
    "    y = layers.Flatten()(y)\n",
    "    y = keras.Model(inputs=input_mhc,outputs=y)\n",
    "\n",
    "    combined = layers.concatenate([x.output,y.output])\n",
    "    z = layers.Dense(128,activation='relu')(combined)\n",
    "    z = layers.Dropout(0.2)(z)\n",
    "    z = layers.Dense(1,activation='sigmoid')(z)\n",
    "\n",
    "    model = keras.Model(inputs=[input_pep,input_mhc],outputs=z)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de75dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = buildCNN()\n",
    "cnn_model.compile(\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    )\n",
    "\n",
    "callback_val = keras.callbacks.EarlyStopping(monitor='val_loss', patience=15,restore_best_weights=False)\n",
    "callback_train = keras.callbacks.EarlyStopping(monitor='loss',patience=2,restore_best_weights=False)\n",
    "\n",
    "history = cnn_model.fit(\n",
    "    x=[input1_train,input2_train],   # feed a list into\n",
    "    y=label_train,\n",
    "    validation_data = ([input1_val,input2_val],label_val),\n",
    "    batch_size=128,\n",
    "    epochs=200,\n",
    "    callbacks = [callback_val,callback_train]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc13196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting validation and training loss against number of epochs\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot()\n",
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a291678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting and further evaluating binary classification accuracy\n",
    "predictions = cnn_model.predict([input1_val,input2_val])\n",
    "exact_match = 0\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i]>0.5 and label_val[i]>0.5:\n",
    "        exact_match+=1\n",
    "    elif predictions[i]<=0.5 and label_val[i]<=0.5:\n",
    "        exact_match+=1\n",
    "    else:\n",
    "        continue\n",
    "print(\"Accuracy : \",exact_match/len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bcfa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dumping model to pickle file\n",
    "pickle.dump(cnn_model, open('cnn_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7ffbe6",
   "metadata": {},
   "source": [
    "# Model 2 - ANN - Fully connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa389eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildANN():\n",
    "    input_pep = keras.Input(shape=(10, 12, 1))\n",
    "    input_mhc = keras.Input(shape=(64, 12, 1))\n",
    "\n",
    "    x = layers.Flatten()(input_pep)\n",
    "    x = layers.Dense(128,activation='relu')(x)\n",
    "    x = layers.Dense(64,activation='relu')(x)\n",
    "    x = layers.Dense(32,activation='relu')(x)\n",
    "    x = keras.Model(inputs=input_pep, outputs=x)\n",
    "\n",
    "    y = layers.Flatten()(input_mhc)\n",
    "    y = layers.Dense(512,activation='relu')(y)\n",
    "    y = layers.Dense(256,activation='relu')(y)\n",
    "    y = layers.Dense(128,activation='relu')(y)\n",
    "    y = layers.Dense(64,activation='relu')(y)\n",
    "    y = layers.Dense(32,activation='relu')(y)\n",
    "    y = keras.Model(inputs=input_mhc,outputs=y)\n",
    "\n",
    "    combined = layers.concatenate([x.output,y.output])\n",
    "    z = layers.Dense(64,activation='relu')(combined)\n",
    "#     z = layers.Dropout(0.2)(z)\n",
    "    z = layers.Dense(32,activation='sigmoid')(z)\n",
    "    z = layers.Dropout(0.6)(z)\n",
    "    z = layers.Dense(1,activation='sigmoid')(z)\n",
    "\n",
    "    model = keras.Model(inputs=[input_pep,input_mhc],outputs=z)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11212559",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model = buildANN()\n",
    "ann_model.compile(\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    )\n",
    "\n",
    "callback_val = keras.callbacks.EarlyStopping(monitor='val_loss', patience=15,restore_best_weights=False)\n",
    "callback_train = keras.callbacks.EarlyStopping(monitor='loss',patience=2,restore_best_weights=False)\n",
    "\n",
    "history = ann_model.fit(\n",
    "    x=[input1_train,input2_train],   # feed a list into\n",
    "    y=label_train,\n",
    "    validation_data = ([input1_val,input2_val],label_val),\n",
    "    batch_size=128,\n",
    "    epochs=200,\n",
    "    callbacks = [callback_val,callback_train]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801d871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting validation and training loss against number of epochs\n",
    "plt.plot()\n",
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6143dd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting and further evaluating binary classification accuracy\n",
    "predictions2 = ann_model.predict([input1_val,input2_val])\n",
    "exact_match2 = 0\n",
    "for i in range(len(predictions)):\n",
    "    if predictions2[i]>0.5 and label_val[i]>0.5:\n",
    "        exact_match2+=1\n",
    "    elif predictions2[i]<=0.5 and label_val[i]<=0.5:\n",
    "        exact_match2+=1\n",
    "    else:\n",
    "        continue\n",
    "print(\"Accuracy : \",exact_match2/len(predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a91f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dumping model to pickle file\n",
    "pickle.dump(ann_model, open('ann_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5334d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
